[toc]

# 可汗学院 统计学

https://www.bilibili.com/video/BV1i4411e7sT?p=24&spm_id_from=pageDriver

## 集中趋势

描述一组数据在哪个区间出现更多

### 均值

一般指算数平均数

### 众数

出现最多的数，可以有多个

### 中位数

排序后位于中间或中间两个数的算数平均数的数

### 随机变量

更像是把随机过程映射成具体的数值的函数。例如
$$
X=\left\{
\begin{array}{rcl}
1&\mathrm{for}&明天下雨\\
0&\mathrm{for}&明天不下雨\\
\end{array}
\right.
$$

### 期望

用于描述总体数量无穷时的均值。例如随机变量可以做无数次试验，有无数次取值，因此用有限样本去估计总体的均值，本质和均值是一样的。

## P24 二项分布的期望值

### 二项分布

每次试验相互独立互不干扰

$X$遵从二项分布，取$1$的概率为$p$，取$0$的概率为$1-p$。做$n$次试验，$X$的期望是$E(X)=np$
$$
\begin{aligned}
P(X=k)&=C_{n}^{k}p^k(1-p)^{n-k}\\
E(X)&=\sum_{k=0}^{n}k*P(X=k)\\
&=\sum_{k=1}^{n}k\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\
&=np\sum_{k=1}^{n}\frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k}\\
令a=k-1,b=n-1\\
&=np\sum_{a=0}^{b}\frac{b!}{a!(b-a)!}p^a(1-p)^{b-a}\\
&=np(p+1-p)^b\\
&=np\\
\end{aligned}
$$
实际上用$a,b$代换后求和各项也是二项分布取做$b$次试验取各个值的概率，概率和自然为$1$。

## P25 P26 泊松过程

$$
\begin{aligned}
令n=ax\\
\lim_{n\rightarrow\infin}{(1+\frac{a}{n})^n}
&=\lim_{x\rightarrow\infin}{(1+\frac{1}{x})^{xa}}\\
&=(\lim_{x\rightarrow\infin}{(1+\frac{1}{x})^{x}})^a\\
&=e^a\\
\end{aligned}
$$

随机变量$X$表示一小时内经过的车辆次数，此处假设每个时刻的车流量互不影响相互独立。

用二项分布建模，假设数学期望$E(X)=\lambda=np$，即每小时有$\lambda$辆车经过，则每分钟有一辆车经过的概率为$\frac{\lambda}{60}$，相当于每一分钟做一次试验（有车经过为成功否则失败），每小时做60次试验。由此推得每小时有$k$辆车经过的概率为
$$
P(X=k)=C_{60}^k(\frac{\lambda}{60})^k(1-\frac{\lambda}{60})^{60-k}\\
$$
即60分钟内有k分钟有车经过。

这样并没有解决每分钟有多辆车经过的问题，解决方法是把分钟细化成秒、时刻。

把分钟细分为无限多时刻，二项分布就变成泊松分布。
$$
\begin{aligned}
P(X=k)&=\lim_{n\rightarrow\infin}{C_n^k(\frac{\lambda}{n})^k(1-\frac{\lambda}{n})^{n-k}}\\
&=\lim_{n\rightarrow\infin}{\frac{n(n-1)\cdots(n-k+1)}{n^k}\frac{\lambda^k}{k!}(1-\frac{\lambda}{n})^n(1-\frac{\lambda}{n})^{-k}}\\
&=\frac{\lambda^k}{k!}\lim_{n\rightarrow\infin}{\frac{n(n-1)\cdots(n-k+1)}{n^k}}\lim_{n\rightarrow\infin}{(1+\frac{-\lambda}{n})^n}\lim_{n\rightarrow\infin}{(1-\frac{\lambda}{n})^{-k}}\\
&=\frac{\lambda^k}{k!}\mathrm{e}^{-\lambda}\\
\end{aligned}
$$
实际应用如，测得每小时有9辆车经过，则期望为9，倒推有k辆车经过的概率。

## P27 大数定律

随机变量$X$的期望，即总体的均值为$E(X)=\mu$。做n次观测，得到n次观测的均值$\bar{X_n}$，随着$n\rightarrow\infin,\bar{X_n}\rightarrow\mu$。

在有限次观测中，前面的均值高于期望，不代表后面的均值就会低于期望。每一次的观测，概率都是独立的。大数定律的重点在于无限次观测，因此前面有限次的观测可以忽略不计，有限次高于期望的观测值和无限次趋近于期望值的观测值取平均，最后均值一定会趋近于期望值。

## P28 29 正态分布

### 标准z分数

$\frac{x-\mu}{\sigma}$，表示离均值相差几个标准差

### 正态分布

二项分布是正态分布的一个很好的近似，试验次数越多越接近。

$p(x)=\frac{1}{\sigma\sqrt{2\pi}}\mathrm{e}^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$

概率是曲线下方的面积，通过定积分求。一般不容易求解析解，用数值解近似。

实际中常用累积分布函数（CDF）计算，$CDF(x)=\int_{-\infin}^{x}{p(t)\mathrm{d}{t}}$

## P35 36 37 38 中心极限定理

### 中心极限定理

任何具有良好定义的均值和标准差的分布，样本均值的抽样分布，在抽样次数足够多后，都会近似于正态分布。

例如概率分布不均匀的骰子，一次取样得到一个样本，一个样本有n=4个样本值，每个样本值为投掷骰子的点数。计算每个样本的均值（这里也可以是其他统计量），当取样次数足够多后，均值出现的频率分布近似于正态分布。n越大，近似越快，近似的分布标准差越小（中间更尖，向中间靠拢）。n趋近于无穷时，得到真正的正态分布。反过来，n=1或2显然是不行的。现实中n=10或15就可以很好近似，收敛很快。n趋近无穷且取样次数趋近无穷时，近似分布的均值与原来的概率分布均值一样。

### 偏度

完美正态分布（偏度=0，峰度=0）的图形关于均值对称，如果不对称，右边尾部较长，称为正偏态（右偏态）分布，偏度为正；反之称为负偏态（左偏态）分布，偏度为负。

### 峰度

相对于完美正态分布的图形，峰度为正，峰度越高，峰顶更尖，两侧更厚，称为正峰态分布；峰度为负，峰度越小，峰顶更平，两侧更扁，称为负峰态分布。

### 样本均值的抽样分布的方差与原来的分布的方差关系

样本均值的抽样分布的标准差=均值分布标准差=均值标准误差
$$
\sigma_{\bar{x}}^2=\frac{\sigma^2}{n}\\
$$
n是样本容量

抽样的均值用$\bar{X}$表示，方差用$S^2$表示（分母$n-1$），是对总体统计量的最好估计。

总体均值$\mu$，方差$\sigma^2$。

注意样本均值的抽样分布和单次对总体抽样是不同的。

## P42 伯努利分布

进行一次试验,成功概率为$p$,失败概率为$1-p$，称为伯努利试验。

伯努利试验的结果的分布，称为伯努利分布，也是二项分布在$n=1$的特例。设试验成功记作$1$，失败记作$0$，$X$表示试验结果
$$
\mu=E(X)=p*1+(1-p)*0=p\\
\sigma^2=D(X)=p(1-p)^2+(1-p)(0-p)^2=p(1-p)\\
$$
二项分布是进行$n$次相互独立的伯努利试验的结果的分布。

## P44

用数字说明了为什么样本容量越大，估计出来的误差越小。

## P45 46

通常在样本容量大于30的时候可以假设样本均值抽样分布是正态分布，否则假设为$t$分布。$t$分布两侧尾部更肥，防止样本容量过小低估了标准差。（即假设：抽样分布的值更分散）

t分布的自由度为$n-1$，$n$是样本容量

## P47 48 49 假设检验

药物试验，药物无效做零假设，有效做备择假设。零假设成立的情况下，得到当前结果的概率称为p值。

零假设通常记作$H_0$，备择假设记作$H_1$或$H_a$

例如用药前反应时间均值为1.2秒，零假设是用药后反应时间均值仍为1.2秒，备择假设是用药后反应时间均值小于或大于1.2秒。这称为双侧检验。备择假设为反应时间均值小于1.2秒，称为单侧检验。

样本容量大于等于30时，统计量一般服从正态分布，用z分数计算概率。小于30尤其是小于30很多时，服从t分布，使用t分数。

## P50 第一型错误

Type I Error，即拒绝了正确的零假设。

通常假设检验从假设零假设成立出发，零假设成立，通常均值等于某个值，有另外一个统计量来检验零假设，计算另一个统计量如此极端或者更加极端的概率，如果概率低于某个阈值则拒绝零假设。

也就是说，上述概率不为0，假设为0.5%，则有0.5%的概率，正确的统计量确实处于极端区间，即小概率事件真的发生，即有0.5%的概率零假设正确，拒绝了零假设即为有0.5%的概率犯第一型错误。

## P51 52

常用的求总体均值落在某个区间内，使得总体均值的置信度有95%，思路有

抽样分布的样本均值=总体均值，它是总体均值的最好估计

抽样的结果可以视为在样本容量$n$下进行的随机抽样

随机抽样的样本均值落在抽样分布的样本均值左右某个区间内（计算z分数或者t分数）的概率有95%=随机抽样样本均值落在总体均值左右某个区间内的概率有95%=总体均值落在随机抽样样本均值左右某个区间内的概率有95%=总体均值落在本次抽样的样本均值左右某个区间内的概率有95%（本次抽样是样本容量$n$下进行的随机抽样）

## P53

美国家庭接入网络占比的例题

$n$为样本容量，$p$为样本值取1的概率或者占比，当$np>5$且$n(1-p)>5$时可以假定样本占比的分布为正态分布。

## P54 随机变量的和与差

X和Y是相互独立的随机变量
$$
E(X)=\mu_X\\
Var(X)=E((X-\mu_X)^2)=\sigma_X^2\\
E(Y)=\mu_Y\\
Var(Y)=E((Y-\mu_Y)^2)=\sigma_Y^2\\
E(X+Y)=E(X)+E(Y)\\
Var(X+Y)=\sigma_{X+Y}^2=\sigma_X^2+\sigma_Y^2\\
E(X-Y)=E(X+(-Y))=E(X)+E(-Y)=E(X)-E(Y)\\
\sigma_{X-Y}^2=\sigma_{X+(-Y)}^2=\sigma_X^2+\sigma_{-Y}^2=\sigma_X^2+\sigma_Y^2\\
$$

## P55-P61

涉及随机变量和与差的假设检验例题

## P62-P66

二维空间$n$个点线性回归直线表达式的推导
$$
y=mx+b\\
m=\frac{\overline{x}\ \overline{y}-\overline{xy}}{(\overline{x})^2-\overline{x^2}}\\
b=\overline{y}-m\overline{x}\\
$$

## P68 线性回归的决定系数

SE(squared error)平方误差

$SE_{LINE}$表示拟合的直线上的点与原来的点的竖直距离的和，即
$$
SE_{LINE}=\sum_{i=1}^{n}{(y_i-(mx_i+b))^2}\\
$$
$SE_{\overline{y}}$表示原来的点到代表$y$均值的直线的竖直距离的和，即
$$
SE_{\overline{y}}=\sum_{i=1}^{n}{(y_i-\overline{y})^2}\\
$$
决定系数（判定系数）$r^2=1-\frac{SE_{LINE}}{SE_{\overline{y}}}$，表示$y$的总波动有多少被$x$的波动（或者说拟合的直线）所描述，右边的分式表示$y$的总波动有多少没有被$x$的波动（或者说拟合的直线）所描述。

如果拟合得非常好，则$SE_{LINE}$非常小，$r^2$接近1，反之接近0。

## P71 协方差

两个随机变量的协方差
$$
COV(X,Y)=E[(X-E[X])(Y-E[Y])]\\
$$
协方差表示两个变量多大程度上一同变化

将括号内展开
$$
COV(X,Y)=E[XY]-E[X]E[Y]\\
$$
用样本值对总体做估计，得到
$$
COV(X,Y)=\overline{XY}-\overline{X}\ \overline{Y}\\
$$
上式就是线性回归斜率的分子

如果在总体中取一部分样本，做线性回归，得到的是总体的近似回归线，斜率是对总体回归线斜率的估计
$$
\hat{m}=\frac{\overline{XY}-\overline{X}\ \overline{Y}}{\overline{X^2}-(\overline{X})^2}=\frac{COV(X,Y)}{COV(X,X)}=\frac{COV(X,Y)}{VAR(X)}\\
$$
由定义可以知道一个变量和它自身的协方差就是它自身的方差。

## P72 卡方分布

$\chi^2$分布，它的随机变量由$n$个相互独立的服从标准正态分布的变量的平方和构成，其分布规律称为$\chi^2$分布

$\chi_n^2$表示由$n$个变量的平方和构成，自由度为$n$

用于衡量理想分布和实际取值的误差

如果有$k$个限制条件，则自由度为$n-k$

## P73-74 卡方分布的假设检验例题

经验法则，列联表的自由度是(行数-1)*(列数-1)

## P75-77

总波动=组内波动+组间波动

自由度同理

涉及到F分布的例题

## P78 相关性和因果性

因果性是A导致B

相关性是观测到A和B同时发生，发生A则很有可能同时发生B，或发生B很有可能同时发生A

区别两者很重要，由相关性可能可以得出完全相反的因果性结论，研究中要注意到潜在的原因

## P79 演绎推理和归纳推理

归纳推理是找出规律或者趋势然后外推，并不一定外推之后规律还是对的，只是假设它正确

演绎推理是从一个事实开始演绎（逻辑运算、计算等）得到其他事实，一定是正确的。没有估计，没有推广，没有假设未来的趋势。

估计人口数，是估计未来的事情，不能得到一个真实准确的值，需要找出规律外推，是归纳推理

## P80-85 演绎推理和归纳推理的例题

完结撒花。

